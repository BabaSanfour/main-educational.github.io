# Program

(program:supervised_learning)=
## Supervised learning using scikit-learn

### Instructor
::::{grid}
:::{grid-item-card} Nikhil Bhagwat
:margin: 3
:columns: 12 6 3 3
:link: https://github.com/nikhil153
:img-top: https://avatars.githubusercontent.com/u/7978607?v=4
:::
::::

**Nikhil Bhagwat, PhD** is an Academic Associate in the [ORIGAMI lab](https://neurodatascience.github.io/) (PI: [Dr. JB Poline](https://www.mcgill.ca/neuro/jean-baptiste-poline-phd)) at McGill University. He completed his PhD thesis on prognostic applications for Alzheimer’s disease using MR imaging and machine-learning (ML) techniques in the [CoBrA Lab](https://www.cobralab.ca/) (PI: [Dr. Mallar Chakravarty](http://cobralab.ca/members/commander/)) at the University of Toronto. Subsequently, he worked as a researcher at the University of Massachusetts and the Allen Institute. His current research interests include disease staging, subtyping, and prognosis using ML models, along with development of neuroinformatics tools for improving [reproducibility](https://github.com/neurodatascience/mr_proc) and [sustainability](https://neuropipelines.github.io/10carbon) of computational pipelines.


### Objectives
  * Define machine-learning nomenclature
  * Describe basics of the “learning” process
  * Explain model design choices and performance trade-offs
  * Introduce model selection and validation frameworks
  * Explain model performance metrics

### Questions you will be able to answer after taking this module:
  * Model training - what is under/over-fitting?
  * Model selection - what is (nested) cross-validation?
  * Model evaluatation - what are type-1 and type-2 errors?

### Materials
::::{grid}

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://github.com/neurodatascience/main-2021-ml-parts-1-2

**The session's repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::
::::

## Model selection and validation using scikit-learn

### Instructor
::::{grid}
:::{grid-item-card} Jean-Baptiste Poline
:margin: 3
:columns: 12 6 3 3
:link: https://www.mcgill.ca/ludmercentre/our-people/principal-investigators/jb-poline
:img-top: images/profile_jbpoline.jpg
:::
::::

**Jean-Baptiste (JB) Poline, PhD**, is an Associate Professor in the Department of Neurology and Neurosurgery at McGill; the co-Chair of the NeuroHub and Chair of the Technical Steering Committee for the Canadian Open Neuroscience Platform (CONP) at the Neuro; and a Principal Investigator at the Ludmer Centre for Neuroinformatics & Mental Health. Among the early pioneers of functional magnetic resonance imaging (fMRI), today, Prof. Jean-Baptiste Poline is a leading researcher in the fields of fMRI, imaging genetics research, and the neuroinformatics technologies that make a big-data approach to neuroscience possible. His work in brain imaging methods, specifically fMRI, is advancing research in neurological and mental disorders by providing unique ways to explore the effects of genetic variations on brain structure, function, and connectivity.

### Objectives
 * Understand how to evaluate the performance of machine learning models.
 * Learn about hyperparameters and model selection.
 * Learn about pitfalls when validating machine learning models and how to easily avoid them using scikit-learn.

### Materials
::::{grid}

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://github.com/neurodatascience/main-2021-ml-parts-1-2

**The session's GitHub repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore the `GitHub` repository {fas}`arrow-right`
:::
::::

## Machine learning in functional MRI using [Nilearn](https://nilearn.github.io)

### Instructors

::::{grid}
:::{grid-item-card} Himanshu Aggarwal
:margin: 3
:columns: 12 6 3 3
:link: https://scholar.google.com/citations?user=E3C4UtMAAAAJ&hl=en
:img-top: images/profile_himanshu.jpeg
:::

:::{grid-item-card} Hao-Ting Wang
:margin: 3
:columns: 12 6 3 3
:link: https://wanghaoting.com
:img-top: https://avatars.githubusercontent.com/u/13743617?v=4
:::
::::

**Himanshu Aggarwal** is a research engineer at the [MIND](https://team.inria.fr/mind/) team, INRIA Saclay, France, and is currently working as a core maintainer on [Nilearn](https://nilearn.github.io/). Previously, he was involved in the Individual Brain Charting (IBC) project with the same team, where he developed various cognitive experiments for task-based fMRI acquisitions, as well as documentation and preprocessing pipelines for the acquired data. His other recent projects involve subject fingerprinting and naturalistic task decoding with functional connectivity and improving task decoding accuracy in scarce data settings.

**Hao-Ting Wang, PhD** is a IVADO postdoctoral fellow at CRIUGM. Her project focuses on discovery of transdiagnostic brain biomarkers amongst neurodegenerative conditions from multiple open access datasets. Her expertise lies in fMRI data processing, functional connectivity, and data workflow construction. She is also a core developer of Nilearn with a focus on fMRI data processing and feature extraction.

### Objectives
 * Understand the structure of functional magnetic resonance imaging data.
 * Generate correlation matrices using fMRI time series (aka "connectomes").
 * Visualize brain maps and connectomes.
 * Train machine learning models to classify subjects by age groups based on brain connectivity.

### Materials
::::{grid}

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://github.com/main-educational/intro_nilearn

**Session's repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://main-educational.github.io/intro_nilearn/intro.html
**The Jupyter Book of this session**
^^^
```{image} images/logo_neurolibre.png
:height: 100
```

Explore and follow the session via `Jupyter Book`.
+++
Get to the session {fas}`arrow-right`
:::
::::

## Machine learning on electro- and magneto-encephalography (EEG/MEG)

### Instructor
::::{grid}
:::{grid-item-card} Annalisa Pascarella
:margin: 3
:columns: 12 6 3 3
:link: https://github.com/annapasca
:img-top: images/profile_annalisa.jpeg
:::

:::{grid-item-card} Vanessa Hadid
:margin: 3
:columns: 12 6 3 3
:link: https://scholar.google.com/citations?user=d9Dr5fkAAAAJ&hl=fr
:img-top: images/profile_vanessa.jpeg
:::
::::

### Objectives
 * Understand the structure of electro- and magneto-encephalography signals
 * Preprocess and visualize MEG/EEG data
 * Learn about the ML techniques to decode evoked and induced MEG/EEG activity
 * Train machine learning models on MEG data using [MNE-python](https://mne.tools/stable/index.html) and PyTorch

### Materials
::::{grid}
:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://github.com/agramfort/22_main_ml_meeg_tuto

**The session's GitHub repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials.
+++
Explore {fas}`arrow-right`
:::
::::


## Experimentation on in silico neural responses
In this session you will use pre-trained encoding models from the [Neural Encoding Dataset](https://github.com/gifale95/NED) (NED) to generate in silico functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) responses to images. You will then leverage the generated in silico neural responses for experimentation. Specifically, using relational neural control (RNC) you will explore in silico fMRI responses for tens of thousands of naturalistic images, to find controlling images that align or disentangle responses for different areas across visual cortex (e.g., V1, V4, FFA, PPA), thus isolating their shared and unique representational content.

### Instructor
::::{grid}
:::{grid-item-card} Alessandro (Ale) Gifford
:margin: 3
:columns: 12 6 3 3
:link: https://github.com/gifale95
:img-top: https://avatars.githubusercontent.com/u/50326481?v=4?s=100
:::
::::

**Ale Gifford** is a PhD student doing research in cognitive computational neuroscience at the [Freie Universität Berlin](https://www.fu-berlin.de/en/index.html), Germany, as part of the [Neural Dynamics of Visual Cognition](https://www.ewi-psy.fu-berlin.de/en/psychologie/arbeitsbereiche/neural_dyn_of_vis_cog/index.html) Lab led by [Radoslaw Cichy](http://userpage.fu-berlin.de/rmcichy/). His work focuses on combining brain data with machine learning to gain novel insight and to develop new tools that advance the theoretical understanding of the algorithms underlying intelligent systems.

### Objectives
This session is divided into two halves, each combining theory and practice.

 * The first half will focus on in silico neural responses. Here you will:
   * Learn the advantages, limitations, and use cases of experimentation on in silico neural responses generated by encoding models;
   * Familiarize with the NED toolbox;
   * Use pre-trained encoding models from NED to generate in silico fMRI and EEG responses to images.

* The second half will focus on applying RNC on in silico fMRI responses to naturalistic images. Here you will:
   * Understand the concept of representational relationships;
   * Familiarize with the RNC paradigm and its use cases;
   * Learn how to use RNC to uncover shared and unique representational content across visual areas.

### Materials

::::{grid}

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://github.com/gifale95/NED

**NED Github repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```
Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://drive.google.com/drive/folders/13aTI5eSK4yDosi63OfsyN20fLo6T5uNj?usp=drive_link

**NED Colab tutorials**
^^^
```{image} images/logo_colab.png
:height: 100
```
Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://github.com/gifale95/RNC

**RNC Github repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```
Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://drive.google.com/drive/folders/1ZTzbeZ1tNtBu2P6fgjbRY8-1KuY-0Kkr?usp=drive_link

**RNC Colab tutorials**
^^^
```{image} images/logo_colab.png
:height: 100
```
Check out the session's materials on `GitHub`.
+++
Explore {fas}`arrow-right`
:::

::::

## Representational similarity analysis in M/EEG

### Instructor
::::{grid}
:::{grid-item-card} Hamza Abdelhedi
:margin: 1
:columns: 12 6 3 3
:link: https://hamzaabdelhedi.com
:img-top: https://avatars.githubusercontent.com/u/46931648?v=4?s=100
:::
::::

**Hamza Abdelhedi** is a PhD student at the faculty of medicine, Université de Montréal in Québec, Canada 🇨🇦, pursuing a degree in Biomedical Engineering. His passion lies in Artificial Intelligence 🤖, Neuroscience 🧠, Python programming 🐍, and open source projects. He thoroughly enjoys learning and contributing in various ways, particularly through coding projects that not only delve into the science but also aim to vulgarize and make it accessible to everyone. In addition to his current studies, he recently obtrained a M.Sc in Artificial Intelligence from Mila/UdeM. He also has a background in Telecommunication Engineering and Mathematics from my educational journey in Tunisia 🇹🇳.


### Objectives 📍
TBA

### Questions you will be able to answer after taking this module 🎯
TBA

### Materials
TBA

## Brain decoding

Within this session, we will go through the basics of running/applying `decoding models`
to `fMRI` data. More precisely, we will explore how we can utilize different `decoding models`
to `estimate`/`predict` what an agent is `perceiving` or `doing` based on `recordings` of `responses`/`activity`.
Given the time restrictions, we will focus on `biological agents`, ie `human participants`, and thus `brain` `responses` obtained from `fMRI`.
### Instructors
::::{grid}
:::{grid-item-card} Peer Herholz
:margin: 1
:columns: 12 6 3 3
:link: https://github.com/PeerHerholz
:img-top: https://avatars.githubusercontent.com/u/20129524?v=4?s=100
:::

:::{grid-item-card} https://github.com/pbarbarant
:margin: 3
:columns: 12 6 3 3
:link: https://github.com/srastegarnia
:img-top: https://avatars.githubusercontent.com/u/104081777?v=4?s=100
:::
::::

**Peer Herholz** is a research affiliate at [The Neuro (Montreal Neurological Institute-Hospital)](https://www.mcgill.ca/neuro/)/[ORIGAMI lab](https://neurodatascience.github.io/) (PI: [Dr. JB Poline](https://www.mcgill.ca/neuro/jean-baptiste-poline-phd)) at [McGill University](https://www.mcgill.ca/) and the [McGovern Institute for Brain Research](https://mcgovern.mit.edu/)/[Senseable Intelligence Group](https://sensein.group/) (PI: [Satra Ghosh](https://satra.cogitatum.org/)). He obtained his PhD in cognitive & computational neuroscience, focusing on auditory processing in humans and machines. Afterwards, he conducted multiple postdocs further working at the intersection between neuroscience & artificial intelligence, as well as expanding the integration of open & reproducible scientific practices therein. Currently, he is working on research questions related to generalization in biological and artificial neural networks, comparing respective representations and their underlying computation.

### Objectives 📍
 * Understand the core aspects & principles of `brain decoding`
   - including `dataset` requirements
 * Explore different `decoding models` that can be applied to `brain data`
   - `Support Vector Machines` (`SVM`s)
   - `Multilayer Perceptrons` (`MLP`s)
   - `Graph-Convolutional Neural Networks` (`GCN`s)
 * Get first hands-on experience using the respective `python` `libraries`

### Questions you will be able to answer after taking this module 🎯
  * What does `brain decoding` entail?
  * What kind of `data` and `information` is required for `brain decoding` analyses?
  * What are examples of suitable `decoding models` and what do they comprise?

### Materials

::::{grid}

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://main-educational.github.io/brain_encoding_decoding
**The Jupyter Book of this session**
^^^
```{image} images/logo_neurolibre.png
:height: 100
```

Explore and follow the session via `Jupyter Book`.
+++
Get to the session {fas}`arrow-right`
:::

:::{grid-item-card}
:margin: 3
:columns: 12 6 3 3
:class-header: bg-light text-center
:link: https://github.com/main-educational/brain_encoding_decoding

**The session's GitHub repository**
^^^
```{image} https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png
:height: 100
```

Check out the session's materials on `GitHub`.
+++
Explore the `GitHub` repository {fas}`arrow-right`
:::
::::

## Towards modelling high-level movement
::::{grid}
:::{grid-item-card} Melanie Segado
:margin: 3
:columns: 12 6 3 3
:link: https://scholar.google.com/citations?user=p8VD3GUAAAAJ&hl=en
:img-top: images/profile_melanie.jpeg
Learn more {fas}`arrow-right`
:::

::::
### Objectives
Quantifying movement and behaviour is essential across all of neuroscience, but traditional methods of collecting and analyzing movement data can be time-consuming, costly, and impractical in many real-world settings. This workshop introduces affordable, efficient strategies using video and pre-trained vision transformers as tools to gather contextually rich datasets, and movement foundation models as a way to combine them into joint insights. While the workshop will focus on human movement, the concepts will be broadly applicable across domains and species.

Participants will:
* gain hands-on experience with leading open-source tools,
* learn to extract detailed movement and contextual information from video using pre-trained models without the need for manual annotation,
* gain a deeper understanding of how to integrate this approach into broader research frameworks in neuroscience.

Specific concepts covered will include pre-trained vision transformers for movement analysis; movement tokenization; movement foundation models; foundation model fine-tuning.
